# ========================================
# LLM API Configuration (for AI Chat with RAG)
# ========================================
# Set LLM_ENABLED=true to use real LLM API instead of simulation
# Supports any OpenAI-compatible endpoint (OpenAI, Azure, Ollama, etc.)

LLM_ENABLED=false
LLM_API_KEY=your-api-key-here
LLM_API_ENDPOINT=https://api.openai.com/v1
LLM_MODEL=gpt-4o-mini

# SSL Verification (set to false for self-signed certs or internal APIs)
LLM_VERIFY_SSL=true

# Streaming (set to true for streaming responses, false for single response)
LLM_STREAM=true

# Examples for different providers:
# OpenAI: https://api.openai.com/v1
# Azure OpenAI: https://your-resource.openai.azure.com/openai/deployments/your-deployment
# Local Ollama: http://localhost:11434/v1
# Together AI: https://api.together.xyz/v1
# Custom internal API: https://your-org.com/xyz-chatbot/v1 (set LLM_VERIFY_SSL=false if needed)

# ========================================
# Legacy OpenAI Configuration (for backward compatibility)
# ========================================
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini

# ========================================
# Application Configuration
# ========================================
DATABASE_URL=sqlite:///./fm_orchestrator.db
UPLOAD_DIR=./uploads
CORS_ORIGINS=http://localhost:5173
